{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqB21QOgMg-G"
   },
   "source": [
    "# Predicting spam mail "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "rALI06-oHusw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YyKe9o2ONeFv"
   },
   "source": [
    "Data Collection & Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "CpStHH8KNcYB"
   },
   "outputs": [],
   "source": [
    "# loading the data from csv file to a pandas Dataframe\n",
    "filepath = '/Users/ramezalghazawi/Desktop/machine learning projects/Classification/mail_data.csv'\n",
    "raw_mail_data = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pdn-7VE2NxsZ",
    "outputId": "28c19d96-23a2-43c0-86ad-5c1aee7f1b58"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message\n",
       "0         ham  Go until jurong point, crazy.. Available only ...\n",
       "1         ham                      Ok lar... Joking wif u oni...\n",
       "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         ham  U dun say so early hor... U c already then say...\n",
       "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...       ...                                                ...\n",
       "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568      ham               Will ü b going to esplanade fr home?\n",
       "5569      ham  Pity, * was in mood for that. So...any other s...\n",
       "5570      ham  The guy did some bitching but I acted like i'd...\n",
       "5571      ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_mail_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_mail_data.isnull().sum().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "yhakjIE1N011"
   },
   "outputs": [],
   "source": [
    "#since we don't have any missing values no need to write a code the replace the null values with a null string\n",
    "mail_data = raw_mail_data.where((pd.notnull(raw_mail_data)),'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "SJey6H-SOWeK",
    "outputId": "af1b0dfd-2ff9-4af9-cfcd-d0c177dd6ab9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>1518</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: put the 10 on the ft\\r\\nthe transport...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>404</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: 3 / 4 / 2000 and following noms\\r\\nhp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>2933</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: calpine daily gas nomination\\r\\n&gt;\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>1409</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: industrial worksheets for august 2000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>4807</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: important online banking alert\\r\\ndea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5171 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 label                                               text  \\\n",
       "0            605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1           2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2           3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3           4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4           2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "...          ...   ...                                                ...   \n",
       "5166        1518   ham  Subject: put the 10 on the ft\\r\\nthe transport...   \n",
       "5167         404   ham  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...   \n",
       "5168        2933   ham  Subject: calpine daily gas nomination\\r\\n>\\r\\n...   \n",
       "5169        1409   ham  Subject: industrial worksheets for august 2000...   \n",
       "5170        4807  spam  Subject: important online banking alert\\r\\ndea...   \n",
       "\n",
       "      label_num  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             1  \n",
       "4             0  \n",
       "...         ...  \n",
       "5166          0  \n",
       "5167          0  \n",
       "5168          0  \n",
       "5169          0  \n",
       "5170          1  \n",
       "\n",
       "[5171 rows x 4 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the dataframe\n",
    "mail_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IbK82N2gOdar",
    "outputId": "4d1840a1-22b5-468f-d4d0-a4528ef4313c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the number of rows and columns in the dataframe\n",
    "mail_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhR4U3ATPBdk"
   },
   "source": [
    "Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "9EW7QSgeOt4p"
   },
   "outputs": [],
   "source": [
    "# label spam mail as 0;  ham mail as 1;\n",
    "\n",
    "mail_data.loc[mail_data['Category'] == 'spam', 'Category',] = 0\n",
    "mail_data.loc[mail_data['Category'] == 'ham', 'Category',] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxZK1fWwPwII"
   },
   "source": [
    "### spam = 0, and ham = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "t8Rt-FaNPtPE"
   },
   "outputs": [],
   "source": [
    "# separating the data as texts and label\n",
    "\n",
    "X = mail_data['Message']\n",
    "\n",
    "Y = mail_data['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QnQeUBGtQPP7",
    "outputId": "a2640f4b-2a1d-4742-9742-3ecbb6017668"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Go until jurong point, crazy.. Available only ...\n",
       "1                           Ok lar... Joking wif u oni...\n",
       "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       U dun say so early hor... U c already then say...\n",
       "4       Nah I don't think he goes to usf, he lives aro...\n",
       "                              ...                        \n",
       "5567    This is the 2nd time we have tried 2 contact u...\n",
       "5568                 Will ü b going to esplanade fr home?\n",
       "5569    Pity, * was in mood for that. So...any other s...\n",
       "5570    The guy did some bitching but I acted like i'd...\n",
       "5571                           Rofl. Its true to its name\n",
       "Name: Message, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cuWDNy5KQQjY",
    "outputId": "1a0a109b-d63a-4cf0-fe4e-b486f1d3d623"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       0\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "5567    0\n",
       "5568    1\n",
       "5569    1\n",
       "5570    1\n",
       "5571    1\n",
       "Name: Category, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvHyqdH8QZPH"
   },
   "source": [
    "### Splitting the data into training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "RO2GmbSNQSQH"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tS2c7A4NRa46",
    "outputId": "5d44247f-65d0-457d-8a94-0fd8b45a3b72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X :  (5572,), shape of X_train : (4457,), shape of X_test (1115,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape of X :  {X.shape}, shape of X_train : {X_train.shape}, shape of X_test {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYQpiACGSBYM"
   },
   "source": [
    "### Extraction the Feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "nLs847nSRibm"
   },
   "outputs": [],
   "source": [
    "# transform the text data to feature vectors using TfidfVectorizer so that it can be used as input to the Logistic regression\n",
    "\n",
    "feature_extraction = TfidfVectorizer(min_df = 1, stop_words='english', lowercase='True')\n",
    "\n",
    "X_train_features = feature_extraction.fit_transform(X_train)\n",
    "X_test_features = feature_extraction.transform(X_test)\n",
    "\n",
    "# convert Y_train and Y_test values as integers\n",
    "\n",
    "Y_train = Y_train.astype('int')\n",
    "Y_test = Y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "dBMAcw9RUkUY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3075                  Don know. I did't msg him recently.\n",
       "1787    Do you know why god created gap between your f...\n",
       "1614                         Thnx dude. u guys out 2nite?\n",
       "4304                                      Yup i'm free...\n",
       "3266    44 7732584351, Do you want a New Nokia 3510i c...\n",
       "                              ...                        \n",
       "789     5 Free Top Polyphonic Tones call 087018728737,...\n",
       "968     What do u want when i come back?.a beautiful n...\n",
       "1667    Guess who spent all last night phasing in and ...\n",
       "3321    Eh sorry leh... I din c ur msg. Not sad alread...\n",
       "1688    Free Top ringtone -sub to weekly ringtone-get ...\n",
       "Name: Message, Length: 4457, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "1NFuGogZUpt0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4457x7431 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 34775 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q86FvELbU_SV"
   },
   "source": [
    "### Training the Model using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "1JeAOwzpUv0V"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWGRHWAPVI_z",
    "outputId": "1c5e15dd-0e07-4871-c4fa-b908ee400b55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the Logistic Regression model with the training data\n",
    "model.fit(X_train_features, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZ01fa8dVeL5"
   },
   "source": [
    "Evaluating the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "ExiF2kKxVYtC"
   },
   "outputs": [],
   "source": [
    "# prediction on training data\n",
    "\n",
    "prediction_on_training_data = model.predict(X_train_features)\n",
    "accuracy_on_training_data = accuracy_score(Y_train, prediction_on_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o7t4DI5UWCkB",
    "outputId": "49fafbb0-0e7f-40c7-9ab7-4aea165731ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data : 0.9670181736594121\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on training data : {accuracy_on_training_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "cTin5rXTWKg3"
   },
   "outputs": [],
   "source": [
    "# prediction on test data\n",
    "\n",
    "prediction_on_test_data = model.predict(X_test_features)\n",
    "accuracy_on_test_data = accuracy_score(Y_test, prediction_on_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4gvoMK4OWnJY",
    "outputId": "7bf56da4-1987-4828-ea00-95c30fb083d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data : 0.9659192825112107\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on test data : {accuracy_on_test_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXdOKxYAXaHC"
   },
   "source": [
    "### Building a Predictive System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h60z1__mWql6",
    "outputId": "3aac53f3-13f2-4afb-e9f2-75d337cbcd44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Ham mail\n"
     ]
    }
   ],
   "source": [
    "#testing an accual spam email from my mailbox \n",
    "input_mail = [\"We the IMF wish to inform you that your total compensation fund of $2.7Million USA Dollars will be transferring to you daily $5,100 through Western Union. So contact Mr. Terry Young.\"]\n",
    "\n",
    "# convert text to feature vectors using a simple if else statment to diplay spam or ham \n",
    "input_data_features = feature_extraction.transform(input_mail)\n",
    "\n",
    "# making prediction\n",
    "\n",
    "prediction = model.predict(input_data_features)\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "if (prediction[0]==1):\n",
    "  print('Ham mail')\n",
    "\n",
    "else:\n",
    "  print('Spam mail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a real world example produceed a False Positive, it might be because of the dataset not having wide range of samples, so i will use another dataset and try to see if it will predict the spam email correctly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Ham mail\n"
     ]
    }
   ],
   "source": [
    "#but before doing that we will try another example \n",
    "\n",
    "\n",
    "#testing an accual spam email from my mailbox \n",
    "input_mail = [\"We have determined that you are eligible to receive a tax refund of 209.27 GBP. Please submit the tax refund request\"]\n",
    "\n",
    "# convert text to feature vectors using a simple if else statment to diplay spam or ham \n",
    "input_data_features = feature_extraction.transform(input_mail)\n",
    "\n",
    "# making prediction\n",
    "\n",
    "prediction = model.predict(input_data_features)\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "if (prediction[0]==1):\n",
    "  print('Ham mail')\n",
    "\n",
    "else:\n",
    "  print('Spam mail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data from csv file to a pandas Dataframe\n",
    "filepath = '/Users/ramezalghazawi/Desktop/machine learning projects/Classification/spam_ham_dataset.csv'\n",
    "raw_mail_data_2 = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>1518</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: put the 10 on the ft\\r\\nthe transport...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>404</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: 3 / 4 / 2000 and following noms\\r\\nhp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>2933</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: calpine daily gas nomination\\r\\n&gt;\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>1409</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: industrial worksheets for august 2000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>4807</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: important online banking alert\\r\\ndea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5171 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 label                                               text  \\\n",
       "0            605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1           2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2           3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3           4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4           2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "...          ...   ...                                                ...   \n",
       "5166        1518   ham  Subject: put the 10 on the ft\\r\\nthe transport...   \n",
       "5167         404   ham  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...   \n",
       "5168        2933   ham  Subject: calpine daily gas nomination\\r\\n>\\r\\n...   \n",
       "5169        1409   ham  Subject: industrial worksheets for august 2000...   \n",
       "5170        4807  spam  Subject: important online banking alert\\r\\ndea...   \n",
       "\n",
       "      label_num  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             1  \n",
       "4             0  \n",
       "...         ...  \n",
       "5166          0  \n",
       "5167          0  \n",
       "5168          0  \n",
       "5169          0  \n",
       "5170          1  \n",
       "\n",
       "[5171 rows x 4 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_mail_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if there is a missing values \n",
    "raw_mail_data_2.isnull().sum().all()\n",
    "#no missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the data as texts and label\n",
    "\n",
    "X_2 = raw_mail_data_2['text']\n",
    "\n",
    "Y_2 = raw_mail_data_2['label_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, Y_train_2, Y_test_2 = train_test_split(X_2, Y_2, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the text data to feature vectors using TfidfVectorizer so that it can be used as input to the Logistic regression\n",
    "\n",
    "feature_extraction_2 = TfidfVectorizer(min_df = 1, stop_words='english', lowercase='True')\n",
    "\n",
    "X_train_features_2 = feature_extraction_2.fit_transform(X_train_2)\n",
    "X_test_features_2 = feature_extraction_2.transform(X_test_2)\n",
    "\n",
    "# convert Y_train and Y_test values as integers\n",
    "\n",
    "Y_train_2 = Y_train_2.astype('int')\n",
    "Y_test_2 = Y_test_2.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the Logistic Regression model with the training data\n",
    "model_2.fit(X_train_features_2, Y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on training data\n",
    "\n",
    "prediction_on_training_data_2 = model_2.predict(X_train_features_2)\n",
    "accuracy_on_training_data_2 = accuracy_score(Y_train_2, prediction_on_training_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data 2 : 0.9970986460348162\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on training data 2 : {accuracy_on_training_data_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on test data\n",
    "\n",
    "prediction_on_test_data_2 = model_2.predict(X_test_features_2)\n",
    "accuracy_on_test_data_2 = accuracy_score(Y_test_2, prediction_on_test_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data : 0.9806763285024155\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on test data : {accuracy_on_test_data_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Ham mail\n",
      "[1]\n",
      "Ham mail\n"
     ]
    }
   ],
   "source": [
    "#testing an accual spam email from my mailbox \n",
    "input_mail_2 = [\"We the IMF wish to inform you that your total compensation fund of $2.7Million USA Dollars will be transferring to you daily $5,100 through Western Union. So contact Mr. Terry Young.\"]\n",
    "input_mail_2_e = [\"We have determined that you are eligible to receive a tax refund of 209.27 GBP. Please submit the tax refund request\"]\n",
    "# convert text to feature vectors using a simple if else statment to diplay spam or ham \n",
    "input_data_features_2 = feature_extraction.transform(input_mail_2)\n",
    "input_data_features_2_e = feature_extraction.transform(input_mail_2_e)\n",
    "# making prediction\n",
    "\n",
    "prediction_2 = model.predict(input_data_features_2)\n",
    "print(prediction)\n",
    "if (prediction[0]==1):\n",
    "  print('Ham mail')\n",
    "\n",
    "else:\n",
    "  print('Spam mail')\n",
    "prediction_2_e = model.predict(input_data_features_2_e)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0]==1):\n",
    "  print('Ham mail')\n",
    "\n",
    "else:\n",
    "  print('Spam mail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### also in the second example it did not recognises the spam email \n",
    "### in the two examples it output the same as the last dataset \n",
    "### need to see the look more into this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project 17. Spam Mail Prediction using Machine Learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
